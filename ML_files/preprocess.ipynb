{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\anand\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\lightfm\\_lightfm_fast.py:9: UserWarning: LightFM was compiled without OpenMP support. Only a single thread will be used.\n",
      "  warnings.warn('LightFM was compiled without OpenMP support. '\n"
     ]
    }
   ],
   "source": [
    "from lightfm import LightFM\n",
    "import scipy.sparse as sp\n",
    "from scipy.sparse import vstack\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class recommender:\n",
    "    def __init__(self,file_model,item_prop,n_items):\n",
    "        self.n_items=n_items\n",
    "        self.file_model=file_model\n",
    "        self.item_prop=item_prop\n",
    "        store_model=open(self.file_model,'rb')\n",
    "        store_item_prop=open(self.item_prop,'rb')\n",
    "        self.model=pickle.load(store_model)\n",
    "        self.item_to_property_matrix_sparse=pickle.load(store_item_prop)\n",
    "    def get_predictions(self,user_id):\n",
    "        pid_array = np.arange(self.n_items, dtype=np.int32)\n",
    "        predictions = self.model.predict(user_id,pid_array,item_features=self.item_to_property_matrix_sparse,num_threads=4)\n",
    "        return predictions \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrain(events,items):\n",
    "    user_activity_count = dict()\n",
    "    for row in events.itertuples():\n",
    "        if row.visitorid not in user_activity_count:\n",
    "            user_activity_count[row.visitorid] = {'view':0 , 'addtocart':0, 'transaction':0};\n",
    "        if row.event == 'addtocart':\n",
    "            user_activity_count[row.visitorid]['addtocart'] += 1 \n",
    "        elif row.event == 'transaction':\n",
    "            user_activity_count[row.visitorid]['transaction'] += 1\n",
    "        elif row.event == 'view':\n",
    "            user_activity_count[row.visitorid]['view'] += 1 \n",
    "\n",
    "    d = pd.DataFrame(user_activity_count)\n",
    "    dataframe = d.transpose()\n",
    "    # Activity range\n",
    "    dataframe['activity'] = dataframe['view'] + dataframe['addtocart'] + dataframe['transaction']\n",
    "    # removing users with only a single view\n",
    "    cleaned_data = dataframe[dataframe['activity']!=1]\n",
    "    # all users contains the userids with more than 1 activity in the events (4lac)\n",
    "    all_users = set(cleaned_data.index.values)\n",
    "    all_items = set(events['itemid'])\n",
    "    # todo: we need to clear items which are only viewed once\n",
    "\n",
    "    visitorid_to_index_mapping  = {}\n",
    "    itemid_to_index_mapping  = {}\n",
    "    vid = 0\n",
    "    iid = 0\n",
    "    for row in events.itertuples():\n",
    "        if row.visitorid in all_users and row.visitorid not in visitorid_to_index_mapping:\n",
    "            visitorid_to_index_mapping[row.visitorid] = vid\n",
    "            vid = vid + 1\n",
    "\n",
    "        if row.itemid in all_items and row.itemid not in itemid_to_index_mapping:\n",
    "            itemid_to_index_mapping[row.itemid] = iid\n",
    "            iid = iid + 1\n",
    "    n_users = len(all_users)\n",
    "    n_items = len(all_items)\n",
    "    user_to_item_matrix = sp.dok_matrix((n_users, n_items), dtype=np.int8)\n",
    "    # We need to check whether we need to add the frequency of view, addtocart and transation.\n",
    "    # Currently we are only taking a single value for each row and column.\n",
    "    action_weights = [1,2,3]\n",
    "\n",
    "    for row in events.itertuples():\n",
    "        if row.visitorid not in all_users:\n",
    "            continue\n",
    "\n",
    "\n",
    "        mapped_visitor_id = visitorid_to_index_mapping[row.visitorid]\n",
    "        mapped_item_id    = itemid_to_index_mapping[row.itemid]\n",
    "\n",
    "        value = 0\n",
    "        if row.event == 'view':\n",
    "            value = action_weights[0]\n",
    "        elif row.event == 'addtocart':\n",
    "            value = action_weights[1]        \n",
    "        elif row.event == 'transaction':\n",
    "            value = action_weights[2]\n",
    "\n",
    "        current_value = user_to_item_matrix[mapped_visitor_id, mapped_item_id]\n",
    "        if value>current_value:\n",
    "            user_to_item_matrix[mapped_visitor_id, mapped_item_id] = value\n",
    "\n",
    "    user_to_item_matrix = user_to_item_matrix.tocsr()\n",
    "    all_items = set(events['itemid'])\n",
    "    filtered_items = items[items.itemid.isin(all_items)]\n",
    "    fake_itemid = []\n",
    "    fake_timestamp = []\n",
    "    fake_property = []\n",
    "    fake_value = []\n",
    "    all_items_with_property = set(items.itemid)\n",
    "    for itx in list(all_items):\n",
    "        if itx not in all_items_with_property:\n",
    "            fake_itemid.insert(0, itx)\n",
    "            fake_timestamp.insert(0, 0)\n",
    "            fake_property.insert(0, 888)\n",
    "            fake_value.insert(0, 0)\n",
    "\n",
    "    fake_property_dict = {'itemid':fake_itemid, 'timestamp':fake_timestamp, 'property':fake_property,\n",
    "                         'value':fake_value}\n",
    "\n",
    "    fake_df = pd.DataFrame(fake_property_dict, columns=filtered_items.columns.values)\n",
    "    filtered_items = pd.concat([filtered_items, fake_df])\n",
    "    filtered_items['itemid'] = filtered_items['itemid'].apply(lambda x: itemid_to_index_mapping[x])\n",
    "    filtered_items = filtered_items.sort_values('timestamp', ascending=False).drop_duplicates(['itemid','property'])\n",
    "    filtered_items.sort_values(by='itemid', inplace=True)\n",
    "    item_to_property_matrix = filtered_items.pivot(index='itemid', columns='property', values='value')\n",
    "    useful_cols = list()\n",
    "    cols = item_to_property_matrix.columns\n",
    "    for col in cols:\n",
    "        value = len(item_to_property_matrix[col].value_counts())\n",
    "        if value < 50:\n",
    "            useful_cols.insert(0, col)\n",
    "    item_to_property_matrix = item_to_property_matrix[useful_cols]\n",
    "    item_to_property_matrix_one_hot_sparse = pd.get_dummies(item_to_property_matrix)\n",
    "    item_to_property_matrix_sparse = csr_matrix(item_to_property_matrix_one_hot_sparse.values)\n",
    "    return (user_to_item_matrix,item_to_property_matrix_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train(ratings, pct_test = 0.2):\n",
    "    test_set = ratings.copy() # Make a copy of the original set to be the test set. \n",
    "    test_set[test_set != 0] = 1 # Store the test set as a binary preference matrix\n",
    "    training_set = ratings.copy() # Make a copy of the original data we can alter as our training set. \n",
    "    nonzero_inds = training_set.nonzero() # Find the indices in the ratings data where an interaction exists\n",
    "    nonzero_pairs = list(zip(nonzero_inds[0], nonzero_inds[1])) # Zip these pairs together of user,item index into list\n",
    "    random.seed(0) # Set the random seed to zero for reproducibility\n",
    "    num_samples = int(np.ceil(pct_test*len(nonzero_pairs))) # Round the number of samples needed to the nearest integer\n",
    "    samples = random.sample(nonzero_pairs, num_samples) # Sample a random number of user-item pairs without replacement\n",
    "    user_inds = [index[0] for index in samples] # Get the user row indices\n",
    "    item_inds = [index[1] for index in samples] # Get the item column indices\n",
    "    training_set[user_inds, item_inds] = 0 # Assign all of the randomly chosen user-item pairs to zero\n",
    "    training_set.eliminate_zeros() # Get rid of zeros in sparse array storage after update to save space\n",
    "    return training_set, test_set, list(set(user_inds)) # Output the unique list of user rows that were altered  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "r=recommender('model.pickle','item_to_property_matrix_sparse.pickle',88000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=open('model.pickle','rb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=pickle.load(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.72322857,  1.51320255, -0.35197493, ...,  1.18143356,\n",
       "        0.82504654,  0.06508896])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.get_predictions(12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
